<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	xmlns:georss="http://www.georss.org/georss" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:media="http://search.yahoo.com/mrss/"
	>

<channel>
	<title>in   theory</title>
	<atom:link href="https://lucatrevisan.wordpress.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://lucatrevisan.wordpress.com</link>
	<description>&#34;Marge, I agree with you - in theory. In theory, communism works. In theory.&#34; -- Homer Simpson</description>
	<lastBuildDate>Sat, 08 Oct 2016 03:34:18 +0000</lastBuildDate>
	<language>en</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>http://wordpress.com/</generator>
<cloud domain='lucatrevisan.wordpress.com' port='80' path='/?rsscloud=notify' registerProcedure='' protocol='http-post' />
<image>
		<url>https://s2.wp.com/i/buttonw-com.png</url>
		<title>in   theory</title>
		<link>https://lucatrevisan.wordpress.com</link>
	</image>
	<atom:link rel="search" type="application/opensearchdescription+xml" href="https://lucatrevisan.wordpress.com/osd.xml" title="in   theory" />
	<atom:link rel='hub' href='https://lucatrevisan.wordpress.com/?pushpress=hub'/>
	<item>
		<title>Avi60: Zero Knowledge for all NP</title>
		<link>https://lucatrevisan.wordpress.com/2016/10/07/avi60-zero-knowledge-for-all-np/</link>
		<comments>https://lucatrevisan.wordpress.com/2016/10/07/avi60-zero-knowledge-for-all-np/#respond</comments>
		<pubDate>Sat, 08 Oct 2016 03:34:14 +0000</pubDate>
		<dc:creator><![CDATA[luca]]></dc:creator>
				<category><![CDATA[theory]]></category>
		<category><![CDATA[Avi Wigderson]]></category>
		<category><![CDATA[things that are excellent]]></category>
		<category><![CDATA[Zero Knowledge]]></category>

		<guid isPermaLink="false">http://lucatrevisan.wordpress.com/?p=3360</guid>
		<description><![CDATA[1982 was the annus mirabilis of the foundations of cryptography. In their paper &#8220;probabilistic encryption,&#8221; Goldwasser and Micali introduced two rigorous definitions of security for encryption, which they proved to be equivalent. One definition required the distributions of encryptions of &#8230; <a href="https://lucatrevisan.wordpress.com/2016/10/07/avi60-zero-knowledge-for-all-np/">Continue reading <span class="meta-nav">&#8594;</span></a><img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3360&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></description>
				<content:encoded><![CDATA[<p>1982 was the <i>annus mirabilis</i> of the foundations of cryptography. In their paper &#8220;probabilistic encryption,&#8221; Goldwasser and Micali introduced two rigorous definitions of security for encryption, which they proved to be equivalent. One definition required the distributions of encryptions of any two messages to be computationally indistinguishable (a concept they introduce in the paper), the other, which they call semantic security, is the property that whatever can be efficiently computed about a message given the cyphertext can also be efficiently computed without the cyphertext. Later the same year, Blum and Micali gave a rigorous definitions of security for pseudorandom generators, and Yao wrapped all these results in a more general framework requiring generic, rather than number-theoretic, assumptions.</p>
<p>The concept of semantic security inspired most subsequent definitions, and proofs, of security based on the concept of simulation. Instead of trying to specify a list of things than adversary should not be able to do, one defines an idealized model in which the adversary has no access to private and encrypted data, and one <i>defines</I> a given system to be secure if whatever an attacker can efficiently compute given the ability of eavesdrop (and possibly mount an active attack), can also be efficiently computed in the ideal model. One then <i>proves</i> a system to be secure by developing a <i>simulator</i> in the ideal model for every real-world adversary.</p>
<p>Together with Rackoff, Goldwasser and Micali took this idea one step further from encryption to interactive communication, and came up with the idea of <i>Zero-Knowledge Proofs</i>. A zero-knowledge proof is a probabilistic proof system in which a prover can convince a verifier, with high confidence, of the truth of a statement, with the additional property that there is a <i>simulator</i> that is able to sample from the distribution of verifier&#8217;s views of the interaction. Thus the verifier is convinced of the truth of the statement being proved, but gains no additional information. In their paper, Goldwasser, Micali and Rackoff introduce the concept and present a zero-knowledge proof for a conjecturally intractable number-theoretic problem. The paper was famously rejected several times, eventually appearing in 1985. </p>
<p>The following year, Goldreich, Micali and Avi Wigderson published a paper giving zero knowledge proof systems for all problems in NP. Their work made zero-knowdge proofs a key tool in the design of secure cryptosystem: it was now possible for a party to publish a commitment to a secret <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x" title="x" class="latex" /> and then, at any time, be able to prove that <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x" title="x" class="latex" /> has a certain property without releasing any additional information about <img src="https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="x" title="x" class="latex" />. This ability was a key ingredient in the development of secure multi-party computation in 1987, by the same authors.</p>
<p>So how does one prove in zero knowledge that, say, a graph is 3-colorable? (Once you have zero-knowledge proofs for one NP-complete problems, you immediately have them for all problems in NP.)</p>
<p>Suppose the prover and the verifier know a graph <img src="https://s0.wp.com/latex.php?latex=G&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="G" title="G" class="latex" /> and the prover knows a 3-coloring. A physical analog of the protocol (which can be implemented using the notion of <i>commitment schemes</i>) is the following: the prover randomizes the color labels, then takes <img src="https://s0.wp.com/latex.php?latex=%7CV%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="|V|" title="|V|" class="latex" /> lockboxes, each labeled by a vertex, and puts a piece of paper with the color of vertex <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="v" title="v" class="latex" /> in the lockbox labeled by <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="v" title="v" class="latex" />, for every <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="v" title="v" class="latex" />. The prover locks all the lockboxes, and sends them to the verifier. The verifier picks a random edge <img src="https://s0.wp.com/latex.php?latex=%28u%2Cv%29&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(u,v)" title="(u,v)" class="latex" /> and asks for the keys of the lockboxes for <img src="https://s0.wp.com/latex.php?latex=u&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="u" title="u" class="latex" /> and for <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="v" title="v" class="latex" />. If they contain different colors, the verifier accepts, otherwise it rejects.</p>
<p>The protocol is <i>complete</i>, in the sense that if the graph is 3-colorable and the parties follow the protocol, then the verifier accepts with probability 1.</p>
<p>The protocol is <i>sound</i>, in the sense that if the graph is not 3-colorable, then, no matter what the prover does, there will have to some edge <img src="https://s0.wp.com/latex.php?latex=%28u%2Cv%29&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="(u,v)" title="(u,v)" class="latex" /> such that the lockboxes of <img src="https://s0.wp.com/latex.php?latex=u&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="u" title="u" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="v" title="v" class="latex" /> are the same, and the verifier has probability at least <img src="https://s0.wp.com/latex.php?latex=1%2F%7CE%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="1/|E|" title="1/|E|" class="latex" /> of picking such an edge and rejecting. Thus the verifier accepts with probability at most <img src="https://s0.wp.com/latex.php?latex=1+-+1%2F%7CE%7C&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="1 - 1/|E|" title="1 - 1/|E|" class="latex" />, which can be made negligibly small by repeating the protocol several times.</p>
<p>As per the zero-knowledge property, the view of the verifier is the choice of a random edge, two open lockboxes corresponding to the endpoints of the edge, containing two random different colors, and <img src="https://s0.wp.com/latex.php?latex=%7CV%7C-2&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="|V|-2" title="|V|-2" class="latex" /> unopened lockboxes. A view with such a distribution can be easily sampled, and the same is true when the physical implementation is replaced by a commitment scheme. (Technically, this is argument only establishes <i>honest-verifier zero knowledge</i>, and a bit more work is needed to capture a more general property.)</p><br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/lucatrevisan.wordpress.com/3360/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/lucatrevisan.wordpress.com/3360/" /></a> <img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3360&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></content:encoded>
			<wfw:commentRss>https://lucatrevisan.wordpress.com/2016/10/07/avi60-zero-knowledge-for-all-np/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
	
		<media:content url="http://1.gravatar.com/avatar/1b8146c6b6915dd379892ea751ca5dba?s=96&#38;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D96" medium="image">
			<media:title type="html">luca</media:title>
		</media:content>
	</item>
		<item>
		<title>Avi60</title>
		<link>https://lucatrevisan.wordpress.com/2016/10/04/avi60/</link>
		<comments>https://lucatrevisan.wordpress.com/2016/10/04/avi60/#respond</comments>
		<pubDate>Tue, 04 Oct 2016 16:45:27 +0000</pubDate>
		<dc:creator><![CDATA[luca]]></dc:creator>
				<category><![CDATA[Princeton]]></category>
		<category><![CDATA[theory]]></category>
		<category><![CDATA[3-coloring]]></category>
		<category><![CDATA[Avi Wigderson]]></category>
		<category><![CDATA[things that are excellent]]></category>

		<guid isPermaLink="false">http://lucatrevisan.wordpress.com/?p=3339</guid>
		<description><![CDATA[The festivities in honor of Avi Wigderson&#8217;s 60th birthday start tomorrow in Princeton, with a dream team of speakers. I will not be able to attend, but luckily a livestream will be available. During the week, I will post a &#8230; <a href="https://lucatrevisan.wordpress.com/2016/10/04/avi60/">Continue reading <span class="meta-nav">&#8594;</span></a><img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3339&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></description>
				<content:encoded><![CDATA[<p>The festivities in honor of Avi Wigderson&#8217;s 60th birthday start tomorrow in Princeton, with a dream team of speakers. I will not be able to attend, but luckily a <a href="https://www.math.ias.edu/avi60">livestream</a> will be available.</p>
<p>During the week, I will post a random selection of results of Avi&#8217;s.</p>
<p>Did you know that Avi&#8217;s first paper was an algorithm to color 3-colorable graphs using <img src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="O(&#92;sqrt n)" title="O(&#92;sqrt n)" class="latex" /> colors? Here is the algorithm, which has the flavor of Ramsey theory proofs. </p>
<p>Suppose all nodes have degree <img src="https://s0.wp.com/latex.php?latex=%3C+%5Csqrt+n&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&lt; &#92;sqrt n" title="&lt; &#92;sqrt n" class="latex" />, then we can easily color the graph with <img src="https://s0.wp.com/latex.php?latex=%5Csqrt+n&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;sqrt n" title="&#92;sqrt n" class="latex" /> colors. Otherwise, there is a node <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="v" title="v" class="latex" /> of degree <img src="https://s0.wp.com/latex.php?latex=%5Cgeq+%5Csqrt+n&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;geq &#92;sqrt n" title="&#92;geq &#92;sqrt n" class="latex" />. The neighbors of <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="v" title="v" class="latex" /> induce a bipartite graph (because, in the 3-coloring that we are promised to exist, they are colored with whichever are the two colors that are different from the color of <img src="https://s0.wp.com/latex.php?latex=v&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="v" title="v" class="latex" />), and so we can find in linear time an independent set of size <img src="https://s0.wp.com/latex.php?latex=%5Cgeq+%5Csqrt+n+%2F+2&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;geq &#92;sqrt n / 2" title="&#92;geq &#92;sqrt n / 2" class="latex" />. So we keep finding independent sets (which we assign a color to, and remove) of size <img src="https://s0.wp.com/latex.php?latex=%5Cgeq+%5Csqrt+n+%2F2&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;geq &#92;sqrt n /2" title="&#92;geq &#92;sqrt n /2" class="latex" /> until we get to a point where we know how to color the residual graph with <img src="https://s0.wp.com/latex.php?latex=%5Cleq+%5Csqrt+n&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;leq &#92;sqrt n" title="&#92;leq &#92;sqrt n" class="latex" /> colors, meaning that we can color the whole graph with <img src="https://s0.wp.com/latex.php?latex=%5Cleq+3+%5Csqrt+n&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="&#92;leq 3 &#92;sqrt n" title="&#92;leq 3 &#92;sqrt n" class="latex" /> colors.</p><br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/lucatrevisan.wordpress.com/3339/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/lucatrevisan.wordpress.com/3339/" /></a> <img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3339&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></content:encoded>
			<wfw:commentRss>https://lucatrevisan.wordpress.com/2016/10/04/avi60/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
	
		<media:content url="http://1.gravatar.com/avatar/1b8146c6b6915dd379892ea751ca5dba?s=96&#38;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D96" medium="image">
			<media:title type="html">luca</media:title>
		</media:content>
	</item>
		<item>
		<title>Congratulations to the 2016 Knuth Prize Selection Committee!</title>
		<link>https://lucatrevisan.wordpress.com/2016/09/09/congratulations-to-the-2016-knuth-prize-selection-committee/</link>
		<comments>https://lucatrevisan.wordpress.com/2016/09/09/congratulations-to-the-2016-knuth-prize-selection-committee/#comments</comments>
		<pubDate>Fri, 09 Sep 2016 17:53:34 +0000</pubDate>
		<dc:creator><![CDATA[luca]]></dc:creator>
				<category><![CDATA[theory]]></category>
		<category><![CDATA[Noam Nisan]]></category>
		<category><![CDATA[things that are excellent]]></category>

		<guid isPermaLink="false">http://lucatrevisan.wordpress.com/?p=3291</guid>
		<description><![CDATA[For the excellent choice of recognizing Noam Nisan for his work on complexity lower bounds, derandomization, and mechanism design. Noam is known to readers of in theory for the development of the Nisan-Wigderson pseudorandom generator construction, which remains at the &#8230; <a href="https://lucatrevisan.wordpress.com/2016/09/09/congratulations-to-the-2016-knuth-prize-selection-committee/">Continue reading <span class="meta-nav">&#8594;</span></a><img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3291&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></description>
				<content:encoded><![CDATA[<p>For the <a href="http://www.acm.org/media-center/2016/september/knuth-prize-2016">excellent choice</a> of recognizing Noam Nisan for his work on complexity lower bounds, derandomization, and mechanism design.</p>
<p>Noam is known to readers of <i>in theory</i> for the development of the Nisan-Wigderson pseudorandom generator construction, which remains at the foundation of conditional derandomization results, and for Nisan&#8217;s generator, which is secure against log-space statistical test, and whose <img src="https://s0.wp.com/latex.php?latex=O%28%5Clog%5E2+n%29&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="O(&#92;log^2 n)" title="O(&#92;log^2 n)" class="latex" /> seed length has not been improved upon in the past 25+ years. The modern definition of randomness extractors was made in a paper of Noam and David Zuckerman, which was also motivated by space-bounded derandomization. </p>
<p>Besides introducing almost all the techniques used in the main results on derandomization and pseudorandomness, Noam also introduced many of the techniques that underlie the main lower bound results that we can prove in restricted models, including the idea of approximating functions by polynomials, of looking at partial derivates to obtain artihmetic lower bounds and the connection between rank and communication complexity. With Linial and Mansour, he showed that the Hastad switching lemma could be used to bound the Fourier coefficients of functions computable by bounded-depth circuits, leading to quasi-polynomial learning algorithms for them (and to the realization that bounded-depth circuits cannot realize pseudorandom functions).</p>
<p>On November 27, 1989, Noam sent an email to a group of colleagues with a proof that (a decision problem equivalent to) the permanent had a multi-prover interactive proof; this set in motion a flurry of activity which led in a matter of days to the LFKN paper showing that <img src="https://s0.wp.com/latex.php?latex=P%5E%7B%5C%23+P%7D&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="P^{&#92;# P}" title="P^{&#92;# P}" class="latex" /> had a (one-prover) interactive proof and to Shamir&#8217;s proof that <img src="https://s0.wp.com/latex.php?latex=IP+%3D+PSPACE&#038;bg=ffffff&#038;fg=333333&#038;s=0" alt="IP = PSPACE" title="IP = PSPACE" class="latex" />.</p>
<p>At the end of the 1990s, having done enough to keep the computational complexity community occupied for several subsequent decades, Noam wrote a paper with Amir Ronen called <i>Algorithmic mechanism design.</i> Around the same time, Elias Koutsoupias and Christos Papadimitriou published their work on worst-case equilibria and Tim Roughgarden and Eva Tardos published their work on selfish routing. A couple of years later, Christos gave back-to-back invited talks at SODA 2001, STOC 2001, ICALP 2001 and FOCS 2001 on game theory, and algorithmic game theory and algorithmic mechanism design have gone on to become a major part of theoretical computer science in the subsequent time.</p>
<p>Congratulations again to the prize committee, and please use the comments section to talk about the result of Noam&#8217;s that I didn&#8217;t know well enough to write about.</p><br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/lucatrevisan.wordpress.com/3291/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/lucatrevisan.wordpress.com/3291/" /></a> <img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3291&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></content:encoded>
			<wfw:commentRss>https://lucatrevisan.wordpress.com/2016/09/09/congratulations-to-the-2016-knuth-prize-selection-committee/feed/</wfw:commentRss>
		<slash:comments>7</slash:comments>
	
		<media:content url="http://1.gravatar.com/avatar/1b8146c6b6915dd379892ea751ca5dba?s=96&#38;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D96" medium="image">
			<media:title type="html">luca</media:title>
		</media:content>
	</item>
		<item>
		<title>A conversation on what theory has done for us</title>
		<link>https://lucatrevisan.wordpress.com/2016/06/17/a-conversation-on-what-theory-has-done-for-us/</link>
		<comments>https://lucatrevisan.wordpress.com/2016/06/17/a-conversation-on-what-theory-has-done-for-us/#comments</comments>
		<pubDate>Fri, 17 Jun 2016 19:32:31 +0000</pubDate>
		<dc:creator><![CDATA[luca]]></dc:creator>
				<category><![CDATA[history]]></category>
		<category><![CDATA[politics]]></category>
		<category><![CDATA[theory]]></category>

		<guid isPermaLink="false">http://lucatrevisan.wordpress.com/?p=3248</guid>
		<description><![CDATA[[Inspired by Lance Fortnow&#8217;s retrospective post on the &#8220;Karp report,&#8221; Avi Wigderson&#8217;s response, and the Monty Python] And what has the theory of computing done for us in the last twenty years? Differential privacy? Apple just announced it will be &#8230; <a href="https://lucatrevisan.wordpress.com/2016/06/17/a-conversation-on-what-theory-has-done-for-us/">Continue reading <span class="meta-nav">&#8594;</span></a><img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3248&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></description>
				<content:encoded><![CDATA[<p>[Inspired by Lance Fortnow&#8217;s <a href="http://blog.computationalcomplexity.org/2016/06/karp-v-wigderson-20-years-later.html">retrospective post</a> on the &#8220;<a href="https://www.cs.auckland.ac.nz/~cristian/karp-report.pdf">Karp report</a>,&#8221; Avi Wigderson&#8217;s <a href="http://blog.computationalcomplexity.org/2016/06/the-relevance-of-tcs.html">response</a>, and the <a href="https://www.youtube.com/watch?v=ExWfh6sGyso">Monty Python</a>]</p>
<p><i>And what has the theory of computing done for us in the last twenty years?</i></p>
<p>Differential privacy? Apple just announced it will be used in iOS 10</p>
<p>Yes, and the application to <a href="https://arxiv.org/pdf/1411.2664.pdf">preventing false discovery and overfitting</a> is now used in production.</p>
<p><i>Ok, fine, but apart from differential privacy, what has theory done for us in the last twenty years?</i></p>
<p>Quantum algorithms? There wouldn&#8217;t be such a push to realize quantum computers if it wasn&#8217;t for Shor&#8217;s algorithm.</p>
<p>And quantum error correcting! There would be no hope of realizing quantum computers without quantum error correction</p>
<p><i>Very well, but apart from differential privacy and quantum computing, what has theory done for us in the &#8230;</i></p>
<p>Streaming algorithms? It all started with a <a href="http://dl.acm.org/citation.cfm?doid=237814.237823">theory paper</a> and now it is a major interdisciplinary effort.</p>
<p><i>Yes, fair enough, but apart from differential privacy, quantum computing, and streaming algorithms, what has theory done for us&#8230;</i></p>
<p>Linear time decodable LDPC error-correcting codes? The <a href="http://www.cs.yale.edu/homes/spielman/Research/ITsuperc.pdf">first generation</a> was not practical, but now they are part of  <a href="https://en.wikipedia.org/wiki/Raptor_code">major standards</a></p>
<p><i>Sure, ok, but apart from differential privacy, quantum computing, streaming algorithms, and error-correcting codes, what has theory&#8230;</i></p>
<p>Homomorphic encryption? The first-generation solutions were inefficient, but it might be only a matter of time before we have usable homomorphic encryption standards.</p>
<p>Linear-time SDD solvers? Algorithms like <a href="https://arxiv.org/pdf/1301.6628.pdf">this</a> and <a href="https://arxiv.org/abs/1605.02353">this</a> are implementable and we may be one more idea away from algorithms that can be put in production.</p>
<p>Sublinear time algorithms like <a href="http://groups.csail.mit.edu/netmit/sFFT/" />sparse FFT</a>?</p>
<p><i>All right! But apart from differential privacy, quantum computing, streaming algorithms, error-correcting codes, homomorphic encryption, linear-time equation solvers and sub-linear time algorithms, what has the theory of computing ever done for us in the past twenty years?</i></p>
<p>. . .</p>
<p>[Could be continued. Indeed, please continue in the comments]</p><br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/lucatrevisan.wordpress.com/3248/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/lucatrevisan.wordpress.com/3248/" /></a> <img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3248&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></content:encoded>
			<wfw:commentRss>https://lucatrevisan.wordpress.com/2016/06/17/a-conversation-on-what-theory-has-done-for-us/feed/</wfw:commentRss>
		<slash:comments>10</slash:comments>
	
		<media:content url="http://1.gravatar.com/avatar/1b8146c6b6915dd379892ea751ca5dba?s=96&#38;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D96" medium="image">
			<media:title type="html">luca</media:title>
		</media:content>
	</item>
		<item>
		<title>Louis CK on the 2016 presidential campaign</title>
		<link>https://lucatrevisan.wordpress.com/2016/06/13/louis-ck-on-the-2016-presidential-campaign/</link>
		<comments>https://lucatrevisan.wordpress.com/2016/06/13/louis-ck-on-the-2016-presidential-campaign/#comments</comments>
		<pubDate>Mon, 13 Jun 2016 23:32:13 +0000</pubDate>
		<dc:creator><![CDATA[luca]]></dc:creator>
				<category><![CDATA[Louis CK]]></category>
		<category><![CDATA[politics]]></category>
		<category><![CDATA[Uncategorized]]></category>

		<guid isPermaLink="false">http://lucatrevisan.wordpress.com/?p=3237</guid>
		<description><![CDATA[From an interview for New York Magazine: It’s like if you were on a plane and you wanted to choose a pilot. You have one person, Hillary, who says, “Here’s my license. Here’s all the thousands of flights that I’ve &#8230; <a href="https://lucatrevisan.wordpress.com/2016/06/13/louis-ck-on-the-2016-presidential-campaign/">Continue reading <span class="meta-nav">&#8594;</span></a><img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3237&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></description>
				<content:encoded><![CDATA[<p>From an  <a href="http://www.vulture.com/2016/06/louis-ck-horace-and-pete-c-v-r.html">interview for New York Magazine</a>:</p>
<blockquote><p> It’s like if you were on a plane and you wanted to choose a pilot. You have one person, Hillary, who says, “Here’s my license. Here’s all the thousands of flights that I’ve flown. Here’s planes I’ve flown in really difficult situations. I’ve had some good flights and some bad flights, but I’ve been flying for a very long time, and I know exactly how this plane works.” Then you’ve got Bernie, who says, “Everyone should get a ride right to their house with this plane.” “Well, how are you going to do that?” “I just think we should. It’s only fair that everyone gets to use the plane equally.” And then Trump says, “I’m going to fly so well. You’re not going to believe how good I’m going to fly this plane, and by the way, Hillary never flew a plane in her life.” “She did, and we have pictures.” “No, she never did it.”</p></blockquote><br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/lucatrevisan.wordpress.com/3237/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/lucatrevisan.wordpress.com/3237/" /></a> <img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3237&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></content:encoded>
			<wfw:commentRss>https://lucatrevisan.wordpress.com/2016/06/13/louis-ck-on-the-2016-presidential-campaign/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
	
		<media:content url="http://1.gravatar.com/avatar/1b8146c6b6915dd379892ea751ca5dba?s=96&#38;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D96" medium="image">
			<media:title type="html">luca</media:title>
		</media:content>
	</item>
		<item>
		<title>The first ever `in theory&#8217; endorsements</title>
		<link>https://lucatrevisan.wordpress.com/2016/06/06/the-first-ever-in-theory-endorsements/</link>
		<comments>https://lucatrevisan.wordpress.com/2016/06/06/the-first-ever-in-theory-endorsements/#comments</comments>
		<pubDate>Mon, 06 Jun 2016 15:38:05 +0000</pubDate>
		<dc:creator><![CDATA[luca]]></dc:creator>
				<category><![CDATA[politics]]></category>
		<category><![CDATA[San Francisco]]></category>

		<guid isPermaLink="false">http://lucatrevisan.wordpress.com/?p=3219</guid>
		<description><![CDATA[So you are a San Francisco Democratic primary voter, a reader of &#8220;in theory,&#8221; and you do not like to think for yourself? You are in luck, because, for the first time ever, we are doing endorsements: Bernie Sanders for &#8230; <a href="https://lucatrevisan.wordpress.com/2016/06/06/the-first-ever-in-theory-endorsements/">Continue reading <span class="meta-nav">&#8594;</span></a><img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3219&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></description>
				<content:encoded><![CDATA[<p>So you are a San Francisco Democratic primary voter, a reader of &#8220;in theory,&#8221; and you do not like to think for yourself? You are in luck, because, for the first time ever, we are doing endorsements:</p>
<p><em>Bernie Sanders</em> for President of the United States</p>
<p><em>Kamala Harris</em> for United States Senator</p>
<p><em>Nancy Pelosi</em> for United States Representative</p>
<p><em>Scott Weiner</em> for California State Senator</p>
<p><em>David Chiu</em> for  California State Assemblyman</p>
<p><em>Victor Hwang</em> for Superior Court Judge</p><br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/lucatrevisan.wordpress.com/3219/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/lucatrevisan.wordpress.com/3219/" /></a> <img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3219&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></content:encoded>
			<wfw:commentRss>https://lucatrevisan.wordpress.com/2016/06/06/the-first-ever-in-theory-endorsements/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
	
		<media:content url="http://1.gravatar.com/avatar/1b8146c6b6915dd379892ea751ca5dba?s=96&#38;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D96" medium="image">
			<media:title type="html">luca</media:title>
		</media:content>
	</item>
		<item>
		<title>Ellenberg&#8217;s announcement of a solution to the cap-set problem</title>
		<link>https://lucatrevisan.wordpress.com/2016/05/17/ellenbergs-announcement-of-a-solution-to-the-cap-set-problem/</link>
		<comments>https://lucatrevisan.wordpress.com/2016/05/17/ellenbergs-announcement-of-a-solution-to-the-cap-set-problem/#comments</comments>
		<pubDate>Wed, 18 May 2016 02:35:47 +0000</pubDate>
		<dc:creator><![CDATA[luca]]></dc:creator>
				<category><![CDATA[math]]></category>
		<category><![CDATA[Additive Combinatorics]]></category>
		<category><![CDATA[cap set]]></category>
		<category><![CDATA[Jordan Ellenberg]]></category>
		<category><![CDATA[polynomial method]]></category>
		<category><![CDATA[things that are excellent]]></category>

		<guid isPermaLink="false">http://lucatrevisan.wordpress.com/?p=3217</guid>
		<description><![CDATA[Jordan Ellenberg has just announced a resolution of the &#8220;cap problem&#8221; using techniques of Croot, Lev and Pach, in a self-contained three-page paper. This is a quite unexpected development for a long-standing open problem in the core of additive combinatorics. &#8230; <a href="https://lucatrevisan.wordpress.com/2016/05/17/ellenbergs-announcement-of-a-solution-to-the-cap-set-problem/">Continue reading <span class="meta-nav">&#8594;</span></a><img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3217&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></description>
				<content:encoded><![CDATA[<p>
 Jordan Ellenberg <a href="https://quomodocumque.wordpress.com/2016/05/13/bounds-for-cap-sets/">has just announced</a> a resolution of the &#8220;cap problem&#8221; using techniques of Croot, Lev and Pach, in a self-contained three-page paper. This is a quite unexpected development for a long-standing open problem in the core of additive combinatorics.</p>
<p>
Perhaps the right starting point for this story is 1936, when Erdos and Turan conjectured that, for every <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{k}" title="{k}" class="latex" />, if <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{A}" title="{A}" class="latex" /> is a subset of <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cldots%2C+N%5C%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;{1,&#92;ldots, N&#92;}}" title="{&#92;{1,&#92;ldots, N&#92;}}" class="latex" /> without <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{k}" title="{k}" class="latex" />-terms arithmetic progressions, then <img src="https://s0.wp.com/latex.php?latex=%7B%7CA%7C%3D+o_k%28n%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{|A|= o_k(n)}" title="{|A|= o_k(n)}" class="latex" />, or, equivalently, that if <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{A}" title="{A}" class="latex" /> is a subset of the integers of positive density, then it must have arbitrarily long arithmetic progressions. Their goal in stating this conjecture was that resolving it would be a stepping stone to proving that the prime numbers have arbitrarily long arithmetic progressions. This vision came true several decades later. Szemeredi proved the conjecture in 1975, and Green and Tao proved that the primes contain arbitrarily long arithmetic progressions in 2004, with Szemeredi&#8217;s theorem being a key ingredient in their proof. </p>
<p>
Rewinding a bit, the first progress on the Erdos-Turan conjecture came from Roth, who proved the <img src="https://s0.wp.com/latex.php?latex=%7Bk%3D3%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{k=3}" title="{k=3}" class="latex" /> case In 1955. Roth&#8217;s proof establishes that if <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Csubseteq+%5C%7B+1%2C%5Cldots%2C+N%5C%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{A &#92;subseteq &#92;{ 1,&#92;ldots, N&#92;}}" title="{A &#92;subseteq &#92;{ 1,&#92;ldots, N&#92;}}" class="latex" /> does not have length-3 arithmetic progressions, then <img src="https://s0.wp.com/latex.php?latex=%7B%7CA%7C%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{|A|}" title="{|A|}" class="latex" /> is at most, roughly <img src="https://s0.wp.com/latex.php?latex=%7BN%2F%5Clog%5Clog+N%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{N/&#92;log&#92;log N}" title="{N/&#92;log&#92;log N}" class="latex" />. Erdos also conjectured that the bound should be <img src="https://s0.wp.com/latex.php?latex=%7Bo%28N%2F%5Clog+N%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{o(N/&#92;log N)}" title="{o(N/&#92;log N)}" class="latex" />, and if this were true it would imply that the primes have infinitely many length-3 arithmetic progressions simply because of their density. </p>
<p>
Roth&#8217;s proof uses Fourier analysis, and Meshulam, in 1995, noted that the proof becomes much cleaner, and it leads to better bounds, if one looks at the analog problem in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+F%7D_p%5En%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;mathbb F}_p^n}" title="{{&#92;mathbb F}_p^n}" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+F%7D_p%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;mathbb F}_p}" title="{{&#92;mathbb F}_p}" class="latex" /> is a finite field (of characteristic different from 2). In this case, the question is how big can <img src="https://s0.wp.com/latex.php?latex=%7BA%5Csubseteq+%7B%5Cmathbb+F%7D_p%5En%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{A&#92;subseteq {&#92;mathbb F}_p^n}" title="{A&#92;subseteq {&#92;mathbb F}_p^n}" class="latex" /> be if it does not have three points on a line. An adaptation of Roth&#8217;s techniques gives an upper bound of the order of <img src="https://s0.wp.com/latex.php?latex=%7Bp%5En%2Fn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{p^n/n}" title="{p^n/n}" class="latex" />, which, for constant <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{p}" title="{p}" class="latex" />, is of the order of <img src="https://s0.wp.com/latex.php?latex=%7BN%2F%5Clog+N%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{N/&#92;log N}" title="{N/&#92;log N}" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{N}" title="{N}" class="latex" /> is the size of the universe of which <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{A}" title="{A}" class="latex" /> is a subset.</p>
<p>
Bourgain introduced a technique to work on <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+Z%7D%2FN%7B%5Cmathbb+Z%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;mathbb Z}/N{&#92;mathbb Z}}" title="{{&#92;mathbb Z}/N{&#92;mathbb Z}}" class="latex" /> &#8220;as if&#8221; it where a vector space over a finite field, and proved upper bounds of the order of <img src="https://s0.wp.com/latex.php?latex=%7BN%2F%5Csqrt+%7B%5Clog+N%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{N/&#92;sqrt {&#92;log N}}" title="{N/&#92;sqrt {&#92;log N}}" class="latex" /> and then <img src="https://s0.wp.com/latex.php?latex=%7BN%2F%28%5Clog+N%29%5E%7B3%2F4%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{N/(&#92;log N)^{3/4}}" title="{N/(&#92;log N)^{3/4}}" class="latex" /> to the size of a subset of <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+1%2C%5Cldots+%2C+N%5C%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;{ 1,&#92;ldots , N&#92;}}" title="{&#92;{ 1,&#92;ldots , N&#92;}}" class="latex" /> without length-3 arithmetic progressions. The latest result in this line is by Sanders, who proved a bound of <img src="https://s0.wp.com/latex.php?latex=%7B%28N+poly%5Clog%5Clog+N%29%2F%5Clog+N%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{(N poly&#92;log&#92;log N)/&#92;log N}" title="{(N poly&#92;log&#92;log N)/&#92;log N}" class="latex" />, very close to Erdos&#8217;s stronger conjecture.</p>
<p>
How far can these results be pushed? A construction of Behrend&#8217;s shows that there is a set <img src="https://s0.wp.com/latex.php?latex=%7BA%5Csubseteq+%5C%7B+1%2C%5Cldots%2C+N%5C%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{A&#92;subseteq &#92;{ 1,&#92;ldots, N&#92;}}" title="{A&#92;subseteq &#92;{ 1,&#92;ldots, N&#92;}}" class="latex" /> with no length-3 arithmetic progression and size roughly <img src="https://s0.wp.com/latex.php?latex=%7BN%2F2%5E%7B%5Csqrt+%7B%5Clog+N%7D%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{N/2^{&#92;sqrt {&#92;log N}}}" title="{N/2^{&#92;sqrt {&#92;log N}}}" class="latex" />. The construction is simple (it is a discretization of a sphere in <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt+%7B%5Clog+N%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sqrt {&#92;log N}}" title="{&#92;sqrt {&#92;log N}}" class="latex" /> dimensions) and it has some unexpected other applications. This means that the right bound in Roth&#8217;s theorem is of the form <img src="https://s0.wp.com/latex.php?latex=%7BN%5E%7B1-o%281%29%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{N^{1-o(1)}}" title="{N^{1-o(1)}}" class="latex" /> and that the &#8220;only&#8221; question is what is the <img src="https://s0.wp.com/latex.php?latex=%7BN%5E%7B-o%281%29%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{N^{-o(1)}}" title="{N^{-o(1)}}" class="latex" /> term.</p>
<p>
In the finite vector space case, there is no analog of Behrend&#8217;s construction, and so the size of say, the largest subset of <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+F%7D_3%5En%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;mathbb F}_3^n}" title="{{&#92;mathbb F}_3^n}" class="latex" /> without three points on a line, was completely open, with an upper bound of the order of <img src="https://s0.wp.com/latex.php?latex=%7B3%5En%2Fn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{3^n/n}" title="{3^n/n}" class="latex" /> and lower bounds of the order of <img src="https://s0.wp.com/latex.php?latex=%7Bc%5En%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{c^n}" title="{c^n}" class="latex" /> for some constant <img src="https://s0.wp.com/latex.php?latex=%7Bc%3C3%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{c&lt;3}" title="{c&lt;3}" class="latex" />. The <em>cap problem</em> was the question of whether the right bound is of the form <img src="https://s0.wp.com/latex.php?latex=%7B3%5E%7B%281-o%281%29%29+%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{3^{(1-o(1)) }}" title="{3^{(1-o(1)) }}" class="latex" /> or not. </p>
<p>
Two weeks ago, <a href="https://arxiv.org/pdf/1605.01506v1.pdf">Croot, Lev and Pach</a> proved that if <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{A}" title="{A}" class="latex" /> is a subset of <img src="https://s0.wp.com/latex.php?latex=%7B%28%7B%5Cmathbb+Z%7D%2F4%7B%5Cmathbb+Z%7D%29%5En%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{({&#92;mathbb Z}/4{&#92;mathbb Z})^n}" title="{({&#92;mathbb Z}/4{&#92;mathbb Z})^n}" class="latex" /> without length-3 arithmetic progressions, then <img src="https://s0.wp.com/latex.php?latex=%7B%7CA%7C%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{|A|}" title="{|A|}" class="latex" /> is at most of the order of <img src="https://s0.wp.com/latex.php?latex=%7B4%5E%7B.926+%5Ccdot+n%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{4^{.926 &#92;cdot n}}" title="{4^{.926 &#92;cdot n}}" class="latex" />. This was a strong indication that the right bound in the cap problem should be sub-exponential.</p>
<p>
This was done a couple of days ago by Ellenberg, who proved an upper bound of the form <img src="https://s0.wp.com/latex.php?latex=%7B%282.756%29%5En%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{(2.756)^n}" title="{(2.756)^n}" class="latex" /> holds in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+F%7D_3%5En%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;mathbb F}_3^n}" title="{{&#92;mathbb F}_3^n}" class="latex" />. The proof is not specific to <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+F%7D_3%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;mathbb F}_3}" title="{{&#92;mathbb F}_3}" class="latex" /> and generalizes to all finite fields.</p>
<p>
Both proofs use the polynomial method. Roughly speaking, the method is to associate a polynomial to a set of interest (for example, by finding a non-zero low-degree polynomial that is zero for all points in the set), and then to proceed with the use of simple properties of polynomials (such as the fact that the space of polynomials of a certain degree has a bounded dimension, or that the set of zeroes of a univariate non-zero polynomial is at most the degree) applied either to the polynomial that we constructed or to the terms of its factorization. </p>
<p>
Let <img src="https://s0.wp.com/latex.php?latex=%7BP_d%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{P_d}" title="{P_d}" class="latex" /> be the vector space of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{n}" title="{n}" class="latex" />-variate polynomials over <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+F%7D_3%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;mathbb F}_3}" title="{{&#92;mathbb F}_3}" class="latex" /> of total degree <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{d}" title="{d}" class="latex" /> that are cube-free (that is, such that all variables occur in monomials with degree 0, 1, or 2), and let <img src="https://s0.wp.com/latex.php?latex=%7Bm_d%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{m_d}" title="{m_d}" class="latex" /> be its dimension.</p>
<p>
If <img src="https://s0.wp.com/latex.php?latex=%7BA%5Csubseteq+%7B%5Cmathbb+F%7D_3%5En%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{A&#92;subseteq {&#92;mathbb F}_3^n}" title="{A&#92;subseteq {&#92;mathbb F}_3^n}" class="latex" /> is a set such that there are no distinct <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{a,b,c}" title="{a,b,c}" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Bb%2Bc%3D0%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{a+b+c=0}" title="{a+b+c=0}" class="latex" /> (a different property from being on a line, but the draft claims that the same argument works for the property of not having three points on a line as well), then Ellenberg shows that</p>
<p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++m_d+-+3%5En+%2B+%7CA%7C+%5Cleq+3+m_%7Bd%2F2%7D+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  m_d - 3^n + |A| &#92;leq 3 m_{d/2} " title="&#92;displaystyle  m_d - 3^n + |A| &#92;leq 3 m_{d/2} " class="latex" /></p>
<p>
then the bound follows from computing that <img src="https://s0.wp.com/latex.php?latex=%7Bm_%7B2n%2F3%7D+%5Cgeq+3%5En+-+c%5En%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{m_{2n/3} &#92;geq 3^n - c^n}" title="{m_{2n/3} &#92;geq 3^n - c^n}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bm_%7Bn%2F3%7D+%5Cleq+c%5En%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{m_{n/3} &#92;leq c^n}" title="{m_{n/3} &#92;leq c^n}" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=%7Bc+%5Capprox+2.756%5Ccdots%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{c &#92;approx 2.756&#92;cdots}" title="{c &#92;approx 2.756&#92;cdots}" class="latex" />.</p>
<p>
The <em>finite field Kakeya problem</em> is another example of a problem that had resisted attacks from powerful Fourier-analytic proofs, and was solved by Zeev Dvir with a <a href="https://terrytao.wordpress.com/2008/03/24/dvirs-proof-of-the-finite-field-kakeya-conjecture/">relatively simple application of the polynomial method</a>. One may hope that the method has not yet exhausted its applicability.</p>
<p>
Gil Kalai has <a href="https://gilkalai.wordpress.com/2016/05/17/polymath-10-emergency-post-5-the-erdos-szemeredi-sunflower-conjecture-is-now-proven/">posted</a> about further consequence of the results of Croot, Lev, Pach and Ellenberg.</p>
<p><br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/lucatrevisan.wordpress.com/3217/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/lucatrevisan.wordpress.com/3217/" /></a> <img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3217&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></content:encoded>
			<wfw:commentRss>https://lucatrevisan.wordpress.com/2016/05/17/ellenbergs-announcement-of-a-solution-to-the-cap-set-problem/feed/</wfw:commentRss>
		<slash:comments>3</slash:comments>
	
		<media:content url="http://1.gravatar.com/avatar/1b8146c6b6915dd379892ea751ca5dba?s=96&#38;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D96" medium="image">
			<media:title type="html">luca</media:title>
		</media:content>
	</item>
		<item>
		<title>Ancient wisdom</title>
		<link>https://lucatrevisan.wordpress.com/2016/05/02/ancient-wisdom/</link>
		<comments>https://lucatrevisan.wordpress.com/2016/05/02/ancient-wisdom/#respond</comments>
		<pubDate>Tue, 03 May 2016 02:51:13 +0000</pubDate>
		<dc:creator><![CDATA[luca]]></dc:creator>
				<category><![CDATA[diversions]]></category>
		<category><![CDATA[San Francisco]]></category>
		<category><![CDATA[science]]></category>

		<guid isPermaLink="false">http://lucatrevisan.wordpress.com/?p=3208</guid>
		<description><![CDATA[[I sneeze several times and then the following conversation happens] J.Z.: In China, we say that if you sneeze once, it means that someone is thinking of you. If you sneeze twice, it means someone is cursing you. Me: and &#8230; <a href="https://lucatrevisan.wordpress.com/2016/05/02/ancient-wisdom/">Continue reading <span class="meta-nav">&#8594;</span></a><img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3208&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></description>
				<content:encoded><![CDATA[<p>[I sneeze several times and then the following conversation happens]</p>
<p>J.Z.: In China, we say that if you sneeze once, it means that someone is thinking of you. If you sneeze twice, it means someone is cursing you.</p>
<p>Me: and what does it mean when I sneeze three times or more?</p>
<p>J.Z.: it means you have a cold.</p><br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/lucatrevisan.wordpress.com/3208/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/lucatrevisan.wordpress.com/3208/" /></a> <img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3208&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></content:encoded>
			<wfw:commentRss>https://lucatrevisan.wordpress.com/2016/05/02/ancient-wisdom/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
	
		<media:content url="http://1.gravatar.com/avatar/1b8146c6b6915dd379892ea751ca5dba?s=96&#38;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D96" medium="image">
			<media:title type="html">luca</media:title>
		</media:content>
	</item>
		<item>
		<title>They are perfect for each other</title>
		<link>https://lucatrevisan.wordpress.com/2016/04/29/they-are-perfect-for-each-other/</link>
		<comments>https://lucatrevisan.wordpress.com/2016/04/29/they-are-perfect-for-each-other/#comments</comments>
		<pubDate>Sat, 30 Apr 2016 05:35:10 +0000</pubDate>
		<dc:creator><![CDATA[luca]]></dc:creator>
				<category><![CDATA[diversions]]></category>
		<category><![CDATA[politics]]></category>
		<category><![CDATA[The rent is too damn high]]></category>
		<category><![CDATA[things that are terrible]]></category>

		<guid isPermaLink="false">http://lucatrevisan.wordpress.com/?p=3183</guid>
		<description><![CDATA[Now that Ted Cruz has chosen his running mate, everybody is wondering: who is going to be Trump&#8217;s pick for vice-president? It would make sense if, to mitigate his negatives, Trump chose a person of color and someone who has &#8230; <a href="https://lucatrevisan.wordpress.com/2016/04/29/they-are-perfect-for-each-other/">Continue reading <span class="meta-nav">&#8594;</span></a><img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3183&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></description>
				<content:encoded><![CDATA[<p>Now that Ted Cruz has chosen his running mate, everybody is wondering: who is going to be Trump&#8217;s pick for vice-president?</p>
<p>It would make sense if, to mitigate his negatives, Trump chose a person of color and someone who has a history of speaking out against income inequality.</p>
<p>He or she would have to be someone who is media-savvy and with some experience running a campaign, but definitely not a career politician. And of course he or she should be someone who endorsed Trump early on, like, say, in January.</p>
<p><span id="more-3183"></span></p>
<p>I can think of only one person: <a href="https://en.wikipedia.org/wiki/Jimmy_McMillan">Jimmy McMillan</a>!</p>
<p><img class="alignnone size-full wp-image-3199" src="https://lucatrevisan.files.wordpress.com/2016/04/480px-jimmy_mcmillan_blue_2_2011_shankbone.jpg?w=584" alt="480px-jimmy_mcmillan_blue_2_2011_shankbone"   /></p><br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/lucatrevisan.wordpress.com/3183/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/lucatrevisan.wordpress.com/3183/" /></a> <img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3183&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></content:encoded>
			<wfw:commentRss>https://lucatrevisan.wordpress.com/2016/04/29/they-are-perfect-for-each-other/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
	
		<media:content url="http://1.gravatar.com/avatar/1b8146c6b6915dd379892ea751ca5dba?s=96&#38;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D96" medium="image">
			<media:title type="html">luca</media:title>
		</media:content>

		<media:content url="http://lucatrevisan.files.wordpress.com/2016/04/480px-jimmy_mcmillan_blue_2_2011_shankbone.jpg" medium="image">
			<media:title type="html">480px-jimmy_mcmillan_blue_2_2011_shankbone</media:title>
		</media:content>
	</item>
		<item>
		<title>CS294 Lecture 20: Properties of Expanders</title>
		<link>https://lucatrevisan.wordpress.com/2016/04/22/cs294-lecture-20-properties-of-expanders/</link>
		<comments>https://lucatrevisan.wordpress.com/2016/04/22/cs294-lecture-20-properties-of-expanders/#respond</comments>
		<pubDate>Fri, 22 Apr 2016 14:47:58 +0000</pubDate>
		<dc:creator><![CDATA[luca]]></dc:creator>
				<category><![CDATA[Expanders]]></category>
		<category><![CDATA[expander mixing lemma]]></category>
		<category><![CDATA[random walks]]></category>

		<guid isPermaLink="false">http://lucatrevisan.wordpress.com/?p=3181</guid>
		<description><![CDATA[In which we prove properties of expander graphs. 1. Quasirandomness of Expander Graphs Recall that if is a -regular graph, and is its adjacency matrix, then, if we call the eigenvalues of with repetitions, we are interested in the parameter &#8230; <a href="https://lucatrevisan.wordpress.com/2016/04/22/cs294-lecture-20-properties-of-expanders/">Continue reading <span class="meta-nav">&#8594;</span></a><img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3181&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></description>
				<content:encoded><![CDATA[<p>
<p>
<em>In which we prove properties of expander graphs.</em></p>
<p>
<span id="more-3181"></span></p>
<p>
<p><b>1. Quasirandomness of Expander Graphs </b></p>
<p><p>
Recall that if <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{G}" title="{G}" class="latex" /> is a <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{d}" title="{d}" class="latex" />-regular graph, and <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{A}" title="{A}" class="latex" /> is its adjacency matrix, then, if we call <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1+%5Cgeq+%5Clambda_2+%5Cgeq+%5Cldots+%5Cgeq+%5Clambda_n%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;lambda_1 &#92;geq &#92;lambda_2 &#92;geq &#92;ldots &#92;geq &#92;lambda_n}" title="{&#92;lambda_1 &#92;geq &#92;lambda_2 &#92;geq &#92;ldots &#92;geq &#92;lambda_n}" class="latex" /> the eigenvalues of <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{A}" title="{A}" class="latex" /> with repetitions, we are interested in the parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_2%28G%29+%3A%3D+%5Cmax_%7Bi%3D2%2C%5Cldots%2Cn%7D+%5C%7B+%7C%5Clambda_i%7C+%5C%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sigma_2(G) := &#92;max_{i=2,&#92;ldots,n} &#92;{ |&#92;lambda_i| &#92;}}" title="{&#92;sigma_2(G) := &#92;max_{i=2,&#92;ldots,n} &#92;{ |&#92;lambda_i| &#92;}}" class="latex" />, and we have</p>
<p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csigma_2%28G%29+%3D+%5Cleft+%5C%7C+A+-+%5Cfrac+dn+J+%5Cright+%5C%7C+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  &#92;sigma_2(G) = &#92;left &#92;| A - &#92;frac dn J &#92;right &#92;| " title="&#92;displaystyle  &#92;sigma_2(G) = &#92;left &#92;| A - &#92;frac dn J &#92;right &#92;| " class="latex" /></p>
<p>
where <img src="https://s0.wp.com/latex.php?latex=%7BJ%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{J}" title="{J}" class="latex" /> is the matrix with a one in each entry, and <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+%5Ccdot+%7C%7C%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{|| &#92;cdot ||}" title="{|| &#92;cdot ||}" class="latex" /> is the matrix norm <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+M+%7C%7C%3A%3D+%5Cmax_%7Bx%2C+%7C%7Cx%7C%7C%3D1%7D+%7C%7CMx%7C%7C%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{|| M ||:= &#92;max_{x, ||x||=1} ||Mx||}" title="{|| M ||:= &#92;max_{x, ||x||=1} ||Mx||}" class="latex" />.</p>
<p>
Our fist result today is to show that, when <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_2%28G%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sigma_2(G)}" title="{&#92;sigma_2(G)}" class="latex" /> is small, the graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{G}" title="{G}" class="latex" /> has the following <em>quasirandomness</em> property: for every two disjoint sets <img src="https://s0.wp.com/latex.php?latex=%7BS%2CT%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{S,T}" title="{S,T}" class="latex" />, the number of edges between <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{S}" title="{S}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{T}" title="{T}" class="latex" /> is close to what we would expect in a random graph of average degree <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{d}" title="{d}" class="latex" />, that is, approximately <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+d%7B%7CV%7C%7D+%7CS%7C+%7CT%7C%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;frac d{|V|} |S| |T|}" title="{&#92;frac d{|V|} |S| |T|}" class="latex" />.</p>
<p>
For two (possibly overlapping) sets of vertices <img src="https://s0.wp.com/latex.php?latex=%7BS%2CT%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{S,T}" title="{S,T}" class="latex" />, we define <img src="https://s0.wp.com/latex.php?latex=%7Bedges_G%28S%2CT%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{edges_G(S,T)}" title="{edges_G(S,T)}" class="latex" /> to be the number of edges with one endpoint in <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{S}" title="{S}" class="latex" /> and one endpoint in <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{T}" title="{T}" class="latex" />, with edges having both endpoints in <img src="https://s0.wp.com/latex.php?latex=%7BS%5Ccap+T%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{S&#92;cap T}" title="{S&#92;cap T}" class="latex" />, if any, counted twice.</p>
<blockquote><p><b>Lemma 1 (Expander Mixing Lemma)</b> <em> Let <img src="https://s0.wp.com/latex.php?latex=%7BG%3D%28V%2CE%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{G=(V,E)}" title="{G=(V,E)}" class="latex" /> be a <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{d}" title="{d}" class="latex" />-regular graph, and let <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{S}" title="{S}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{T}" title="{T}" class="latex" /> be two disjoint subsets of vertices. Then</p>
<p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%7C+edges_G%28S%2CT%29+-+%5Cfrac+d+%7B%7CV%7C%7D+%5Ccdot+%7CS%7C%5Ccdot+%7CT%7C+%5Cright%7C+%5Cleq+%5Csigma_2%28G%29+%5Ccdot+%5Csqrt%7B%7CS%7C%5Ccdot+%7CT%7C%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  &#92;left| edges_G(S,T) - &#92;frac d {|V|} &#92;cdot |S|&#92;cdot |T| &#92;right| &#92;leq &#92;sigma_2(G) &#92;cdot &#92;sqrt{|S|&#92;cdot |T|}" title="&#92;displaystyle  &#92;left| edges_G(S,T) - &#92;frac d {|V|} &#92;cdot |S|&#92;cdot |T| &#92;right| &#92;leq &#92;sigma_2(G) &#92;cdot &#92;sqrt{|S|&#92;cdot |T|}" class="latex" /></p>
<p> </em></p></blockquote>
<p><p>
<em>Proof:</em>  We have</p>
<p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++edges_G%28S%2CT%29+%3D+%7B%5Cbf+1%7D_S%5E%5Ctop+A+%7B%5Cbf+1%7D_T+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  edges_G(S,T) = {&#92;bf 1}_S^&#92;top A {&#92;bf 1}_T " title="&#92;displaystyle  edges_G(S,T) = {&#92;bf 1}_S^&#92;top A {&#92;bf 1}_T " class="latex" /></p>
<p> and
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CS%7C+%7CT%7C+%3D+%7B%5Cbf+1%7D_S%5E%5Ctop+J+%7B%5Cbf+1%7D_T+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  |S| |T| = {&#92;bf 1}_S^&#92;top J {&#92;bf 1}_T " title="&#92;displaystyle  |S| |T| = {&#92;bf 1}_S^&#92;top J {&#92;bf 1}_T " class="latex" /></p>
<p> so
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%7C+edges_G%28S%2CT%29+-+%5Cfrac+d+%7B%7CV%7C%7D+%5Ccdot+%7CS%7C%5Ccdot+%7CT%7C+%5Cright%7C+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  &#92;left| edges_G(S,T) - &#92;frac d {|V|} &#92;cdot |S|&#92;cdot |T| &#92;right| " title="&#92;displaystyle  &#92;left| edges_G(S,T) - &#92;frac d {|V|} &#92;cdot |S|&#92;cdot |T| &#92;right| " class="latex" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Ccdot+%5Cleft%7C+%7B%5Cbf+1%7D_S%5E%5Ctop+A+%7B%5Cbf+1%7D_T+-+%5Cfrac+d+%7B%7CV%7C%7D+%7B%5Cbf+1%7D_S%5E%5Ctop+J+%7B%5Cbf+1%7D_T+%5Cright%7C+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  = &#92;cdot &#92;left| {&#92;bf 1}_S^&#92;top A {&#92;bf 1}_T - &#92;frac d {|V|} {&#92;bf 1}_S^&#92;top J {&#92;bf 1}_T &#92;right| " title="&#92;displaystyle  = &#92;cdot &#92;left| {&#92;bf 1}_S^&#92;top A {&#92;bf 1}_T - &#92;frac d {|V|} {&#92;bf 1}_S^&#92;top J {&#92;bf 1}_T &#92;right| " class="latex" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Ccdot+%5Cleft%7C+%7B%5Cbf+1%7D_S%5E%5Ctop+%5Cleft%28+A+-+%5Cfrac+d+%7B%7CV%7C%7D+J+%5Cright%29+%7B%5Cbf+1%7D_T+%5Cright%7C+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  = &#92;cdot &#92;left| {&#92;bf 1}_S^&#92;top &#92;left( A - &#92;frac d {|V|} J &#92;right) {&#92;bf 1}_T &#92;right| " title="&#92;displaystyle  = &#92;cdot &#92;left| {&#92;bf 1}_S^&#92;top &#92;left( A - &#92;frac d {|V|} J &#92;right) {&#92;bf 1}_T &#92;right| " class="latex" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%7C%7C+%7B%5Cbf+1%7D_S+%7C%7C+%5Ccdot+%5Cleft%5C%7C+A+-+%5Cfrac+d+%7B%7CV%7C%7D+J+%5Cright%5C%7C+%5Ccdot+%5C%7C+%7B%5Cbf+1%7D_T+%5C%7C+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  &#92;leq || {&#92;bf 1}_S || &#92;cdot &#92;left&#92;| A - &#92;frac d {|V|} J &#92;right&#92;| &#92;cdot &#92;| {&#92;bf 1}_T &#92;| " title="&#92;displaystyle  &#92;leq || {&#92;bf 1}_S || &#92;cdot &#92;left&#92;| A - &#92;frac d {|V|} J &#92;right&#92;| &#92;cdot &#92;| {&#92;bf 1}_T &#92;| " class="latex" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Csqrt%7B%7CS%7C%7D+%5Ccdot+%5Csigma_2%28G%29+%5Ccdot+%5Csqrt%7B%7CT%7C%7D+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  = &#92;sqrt{|S|} &#92;cdot &#92;sigma_2(G) &#92;cdot &#92;sqrt{|T|} " title="&#92;displaystyle  = &#92;sqrt{|S|} &#92;cdot &#92;sigma_2(G) &#92;cdot &#92;sqrt{|T|} " class="latex" /></p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%5CBox&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;Box" title="&#92;Box" class="latex" /></p>
<p>
Note that, for every disjoint <img src="https://s0.wp.com/latex.php?latex=%7BS%2CT%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{S,T}" title="{S,T}" class="latex" />, we have <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt+%7B%7CS%7C+%5Ccdot+%7CT%7C%7D+%5Cleq+%7CV%7C%2F2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sqrt {|S| &#92;cdot |T|} &#92;leq |V|/2}" title="{&#92;sqrt {|S| &#92;cdot |T|} &#92;leq |V|/2}" class="latex" />, and so the right-hand side in the expander mixing lemma is at most <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+%7B%5Csigma_2%28G%29%7D%7Bd%7D+%5Ccdot+%7CE%7C%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;frac {&#92;sigma_2(G)}{d} &#92;cdot |E|}" title="{&#92;frac {&#92;sigma_2(G)}{d} &#92;cdot |E|}" class="latex" />, which is a small fraction of the total number of edges if <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sigma_2}" title="{&#92;sigma_2}" class="latex" /> is small compared to <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{d}" title="{d}" class="latex" />.</p>
<p>
<p><b>2. Random Walks in Expanders </b></p>
<p><p>
A <em><img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" />-step random walk</em> is the probabilistic process in which we start at a vertex, then we pick uniformly at random one of the edges incident on the vertices and we move to the other endpoint of the edge, and then repeat this process <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" /> times.</p>
<p>
If <img src="https://s0.wp.com/latex.php?latex=%7BP+%3A%3D+%5Cfrac+1d+A%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{P := &#92;frac 1d A}" title="{P := &#92;frac 1d A}" class="latex" /> is the normalized adjacency matrix of an undirected regular graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{G}" title="{G}" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=%7BP%28u%2Cv%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{P(u,v)}" title="{P(u,v)}" class="latex" /> is the probability that, in one step, a random walk started at <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{u}" title="{u}" class="latex" /> reaches <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{v}" title="{v}" class="latex" />. This is why the normalized adjacency matrix of a regular graph is also called its <em>transition matrix</em>.</p>
<p>
Suppose that we start a random walk at a vertex chosen according to a probability distribution <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+p%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf p}}" title="{{&#92;bf p}}" class="latex" />, which we think of as a vector <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+p%7D+%5Cin+%7B%5Cmathbb+R%7D%5EV%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf p} &#92;in {&#92;mathbb R}^V}" title="{{&#92;bf p} &#92;in {&#92;mathbb R}^V}" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+p%7D%28u%29+%5Cgeq+0%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf p}(u) &#92;geq 0}" title="{{&#92;bf p}(u) &#92;geq 0}" class="latex" /> for every <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{u}" title="{u}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_u+%7B%5Cbf+p%7D%28u%29+%3D+1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sum_u {&#92;bf p}(u) = 1}" title="{&#92;sum_u {&#92;bf p}(u) = 1}" class="latex" />. After taking one step, the probability of being at vertex <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{v}" title="{v}" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_u+%7B%5Cbf+p%7D%28u%29+P%28u%2Cv%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sum_u {&#92;bf p}(u) P(u,v)}" title="{&#92;sum_u {&#92;bf p}(u) P(u,v)}" class="latex" />, which means that the probability distribution after one step is described by the vector <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+p%7D%5E%5Ctop+%5Ccdot+P%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf p}^&#92;top &#92;cdot P}" title="{{&#92;bf p}^&#92;top &#92;cdot P}" class="latex" />, and because of the symmetric of <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{P}" title="{P}" class="latex" />, this is the same as <img src="https://s0.wp.com/latex.php?latex=%7BP+%7B%5Cbf+p%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{P {&#92;bf p}}" title="{P {&#92;bf p}}" class="latex" />.</p>
<p>
Iterating the above reasoning, we see that, after a <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" />-step random walk whose initial vertex is chosen according to distribution <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+p%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf p}}" title="{{&#92;bf p}}" class="latex" />, the last vertex reached by the walk is distributed according to <img src="https://s0.wp.com/latex.php?latex=%7BP%5Et+%7B%5Cbf+p%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{P^t {&#92;bf p}}" title="{P^t {&#92;bf p}}" class="latex" />.</p>
<p>
The parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sigma_2}" title="{&#92;sigma_2}" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=%7BP%5Et%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{P^t}" title="{P^t}" class="latex" /> is equal to <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Csigma_2%28G%29%2Fd%29%5Et%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{(&#92;sigma_2(G)/d)^t}" title="{(&#92;sigma_2(G)/d)^t}" class="latex" />, and so if <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{G}" title="{G}" class="latex" /> has a parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sigma_2}" title="{&#92;sigma_2}" class="latex" /> bounded away from <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{d}" title="{d}" class="latex" />, and if <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" /> is large enough, we have that the parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sigma_2}" title="{&#92;sigma_2}" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=%7BP%5Et%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{P^t}" title="{P^t}" class="latex" /> is very small, and so <img src="https://s0.wp.com/latex.php?latex=%7BP%5Et%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{P^t}" title="{P^t}" class="latex" /> is close to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+1n+J%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;frac 1n J}" title="{&#92;frac 1n J}" class="latex" /> in matrix norm. If <img src="https://s0.wp.com/latex.php?latex=%7BP%5Et%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{P^t}" title="{P^t}" class="latex" /> was actually equal to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+1n+J%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;frac 1n J}" title="{&#92;frac 1n J}" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=%7BP%5Et+%5Ccdot+%7B%5Cbf+p%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{P^t &#92;cdot {&#92;bf p}}" title="{P^t &#92;cdot {&#92;bf p}}" class="latex" /> would be equal to the uniform distribution, for every distribution <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+p%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf p}}" title="{{&#92;bf p}}" class="latex" />. We would thus expect <img src="https://s0.wp.com/latex.php?latex=%7BP%5Et+%5Ccdot+%7B%5Cbf+p%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{P^t &#92;cdot {&#92;bf p}}" title="{P^t &#92;cdot {&#92;bf p}}" class="latex" /> to be close to the uniform distribution for large enough <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" />. </p>
<p>
Before formalizing the above intuition, we need to fix a good measure of distance for distributions. If we think of distributions as vectors, then a possible notion of distance between two distributions is the Euclidean distance between the corresponding vectors. This definition, however, has various shortcoming and, in particular, can assign small distance to distributions that are intuitively very different. For example, suppose that <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+p%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf p}}" title="{{&#92;bf p}}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+q%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf q}}" title="{{&#92;bf q}}" class="latex" /> are distributions that are uniform over a set <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{S}" title="{S}" class="latex" />, and over the complement of <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{S}" title="{S}" class="latex" />, respectively, where <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{S}" title="{S}" class="latex" /> is a set of size <img src="https://s0.wp.com/latex.php?latex=%7B%7CV%7C%2F2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{|V|/2}" title="{|V|/2}" class="latex" />. Then all the entries of <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+p%7D-%7B%5Cbf+q%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf p}-{&#92;bf q}}" title="{{&#92;bf p}-{&#92;bf q}}" class="latex" /> are <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+2%2Fn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;pm 2/n}" title="{&#92;pm 2/n}" class="latex" /> and so <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+%7B%5Cbf+p%7D+-+%7B%5Cbf+q%7D+%7C%7C+%3D+2%2F%5Csqrt+n%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{|| {&#92;bf p} - {&#92;bf q} || = 2/&#92;sqrt n}" title="{|| {&#92;bf p} - {&#92;bf q} || = 2/&#92;sqrt n}" class="latex" />, which is vanishingly small even though distributions over disjoint supports should be considered as maximally different distributions.</p>
<p>
A very good measure is the <em>total variation distance</em>, defined as</p>
<p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmax_%7BS+%5Csubseteq+V%7D+%5Cleft%7C+%5Csum_%7Bv%5Cin+S%7D+%7B%5Cbf+p%7D%28v%29+-+%5Csum_%7Bv%5Cin+S%7D+%7B%5Cbf+q%7D+%28v%29+%5Cright%7C+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  &#92;max_{S &#92;subseteq V} &#92;left| &#92;sum_{v&#92;in S} {&#92;bf p}(v) - &#92;sum_{v&#92;in S} {&#92;bf q} (v) &#92;right| " title="&#92;displaystyle  &#92;max_{S &#92;subseteq V} &#92;left| &#92;sum_{v&#92;in S} {&#92;bf p}(v) - &#92;sum_{v&#92;in S} {&#92;bf q} (v) &#92;right| " class="latex" /></p>
<p>
that is, as the maximum over all events of the difference between the probability of the event happening with respect to one distribution and the probability of it happening with respect to the other distribution. This measure is usually called <em>statistical distance</em> in computer science. It is easy to check that the total variation distance between <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+p%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf p}}" title="{{&#92;bf p}}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+q%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf q}}" title="{{&#92;bf q}}" class="latex" /> is precisely <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+12+%5Ccdot+%7C%7C+%7B%5Cbf+p%7D+-+%7B%5Cbf+q%7D%7C%7C_1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;frac 12 &#92;cdot || {&#92;bf p} - {&#92;bf q}||_1}" title="{&#92;frac 12 &#92;cdot || {&#92;bf p} - {&#92;bf q}||_1}" class="latex" />. Distributions with disjoint support have total variation distance 1, which is largest possible.</p>
<blockquote><p><b>Lemma 2 (Mixing Time of Random Walks in Expanders)</b> <em> Let <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{G}" title="{G}" class="latex" /> be a regular graph, and <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{P}" title="{P}" class="latex" /> be its normalized adjacency matrix. Then for every distribution <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+p%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf p}}" title="{{&#92;bf p}}" class="latex" /> over the vertices and every <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" />, we have</p>
<p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+%7B%5Cbf+u%7D+-+P%5Et+%7B%5Cbf+p%7D+%7C%7C_1+%5Cleq+%5Csqrt+%7B%7CV%7C%7D+%5Ccdot+%28%5Csigma_2%28G%29%2Fd%29%5Et+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  || {&#92;bf u} - P^t {&#92;bf p} ||_1 &#92;leq &#92;sqrt {|V|} &#92;cdot (&#92;sigma_2(G)/d)^t " title="&#92;displaystyle  || {&#92;bf u} - P^t {&#92;bf p} ||_1 &#92;leq &#92;sqrt {|V|} &#92;cdot (&#92;sigma_2(G)/d)^t " class="latex" /></p>
<p> where <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+u%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf u}}" title="{{&#92;bf u}}" class="latex" /> is the uniform distribution.</p>
<p>
In particular, if <img src="https://s0.wp.com/latex.php?latex=%7Bt+%3E+%5Cfrac+%7Bdc%7D+%7Bd-%5Csigma_2%28G%29%7D+%5Ccdot+%5Cln+%5Cfrac+%7B%7CV%7C%7D%7B%5Cepsilon%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t &gt; &#92;frac {dc} {d-&#92;sigma_2(G)} &#92;cdot &#92;ln &#92;frac {|V|}{&#92;epsilon}}" title="{t &gt; &#92;frac {dc} {d-&#92;sigma_2(G)} &#92;cdot &#92;ln &#92;frac {|V|}{&#92;epsilon}}" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7C%7B%5Cbf+u%7D+-+P%5Et+%7B%5Cbf+p%7D%7C%7C_1+%5Cleq+%5Cepsilon%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{||{&#92;bf u} - P^t {&#92;bf p}||_1 &#92;leq &#92;epsilon}" title="{||{&#92;bf u} - P^t {&#92;bf p}||_1 &#92;leq &#92;epsilon}" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{c}" title="{c}" class="latex" /> is an absolute constant. </em></p></blockquote>
<p><p>
<em>Proof:</em>  Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbar+J+%3D+J%2F%7CV%7C%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;bar J = J/|V|}" title="{&#92;bar J = J/|V|}" class="latex" /> be the normalized adjacency matrix of a clique with self-loops. Then, for every distribution <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cbf+p%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{{&#92;bf p}}" title="{{&#92;bf p}}" class="latex" />, we have <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbar+J+%7B%5Cbf+p%7D+%3D+%7B%5Cbf+u%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;bar J {&#92;bf p} = {&#92;bf u}}" title="{&#92;bar J {&#92;bf p} = {&#92;bf u}}" class="latex" />. Recall also that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_2%28G%29+%3D+%7C%7C+P+-+%5Cbar+J%7C%7C%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sigma_2(G) = || P - &#92;bar J||}" title="{&#92;sigma_2(G) = || P - &#92;bar J||}" class="latex" />.</p>
<p>
We have</p>
<p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+%7B%5Cbf+u%7D+-+P%5Et+%7B%5Cbf+p%7D+%7C%7C_1+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  || {&#92;bf u} - P^t {&#92;bf p} ||_1 " title="&#92;displaystyle  || {&#92;bf u} - P^t {&#92;bf p} ||_1 " class="latex" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%5Csqrt%7B%7CV%7C%7D+%5Ccdot+%7C%7C+%7B%5Cbf+u%7D+-+P%5Et+%7B%5Cbf+p%7D+%7C%7C+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  &#92;leq &#92;sqrt{|V|} &#92;cdot || {&#92;bf u} - P^t {&#92;bf p} || " title="&#92;displaystyle  &#92;leq &#92;sqrt{|V|} &#92;cdot || {&#92;bf u} - P^t {&#92;bf p} || " class="latex" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%5Csqrt+%7B%7CV%7C%7D+%5Ccdot+%7C%7C+%5Cbar+J+%7B%5Cbf+p%7D+-+P%5Et+%7B%5Cbf+p%7D+%7C%7C+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  &#92;leq &#92;sqrt {|V|} &#92;cdot || &#92;bar J {&#92;bf p} - P^t {&#92;bf p} || " title="&#92;displaystyle  &#92;leq &#92;sqrt {|V|} &#92;cdot || &#92;bar J {&#92;bf p} - P^t {&#92;bf p} || " class="latex" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%5Csqrt+%7B%7CV%7C%7D+%5Ccdot+%7C%7C+%5Cbar+J+-+P%5Et+%7C%7C+%5Ccdot+%7C%7C%7B%5Cbf+p%7D+%7C%7C+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  &#92;leq &#92;sqrt {|V|} &#92;cdot || &#92;bar J - P^t || &#92;cdot ||{&#92;bf p} || " title="&#92;displaystyle  &#92;leq &#92;sqrt {|V|} &#92;cdot || &#92;bar J - P^t || &#92;cdot ||{&#92;bf p} || " class="latex" /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%5Csqrt%7B%7CV%7C%7D+%5Ccdot+%28%5Csigma_2%28G%29%2Fd%29%5Et+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  &#92;leq &#92;sqrt{|V|} &#92;cdot (&#92;sigma_2(G)/d)^t " title="&#92;displaystyle  &#92;leq &#92;sqrt{|V|} &#92;cdot (&#92;sigma_2(G)/d)^t " class="latex" /></p>
<p> <img src="https://s0.wp.com/latex.php?latex=%5CBox&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;Box" title="&#92;Box" class="latex" /></p>
<p>
The last result that we discussed today is one more instantiation of the general phenomenon that &#8220;if <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_2%28G%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sigma_2(G)}" title="{&#92;sigma_2(G)}" class="latex" /> is small then a result that is true for the clique is true, within some approximation, for <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{G}" title="{G}" class="latex" />.&#8221;</p>
<p>
Suppose that we take a <img src="https://s0.wp.com/latex.php?latex=%7B%28t-1%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{(t-1)}" title="{(t-1)}" class="latex" />-step random walk in a regular graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{G}" title="{G}" class="latex" /> starting from a uniformly distributed initial vertex. If <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{G}" title="{G}" class="latex" /> is a clique with self-loops, then the sequence of <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" /> vertices encountered in the random walk is a sequence of <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" /> independent, uniformly distributed, vertices. In particular, if <img src="https://s0.wp.com/latex.php?latex=%7Bf%3A+V+%5Crightarrow+%5B0.1%5D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{f: V &#92;rightarrow [0.1]}" title="{f: V &#92;rightarrow [0.1]}" class="latex" /> is a bounded function, the Chernoff-Hoeffding bounds tell us that the empirical average of <img src="https://s0.wp.com/latex.php?latex=%7Bf%28%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{f()}" title="{f()}" class="latex" /> over the <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" /> points of the random walk is very close to the true average of <img src="https://s0.wp.com/latex.php?latex=%7Bf%28%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{f()}" title="{f()}" class="latex" />, except with very small probability, that is, if we denote by <img src="https://s0.wp.com/latex.php?latex=%7Bv_1%2C%5Cldots%2Cv_t%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{v_1,&#92;ldots,v_t}" title="{v_1,&#92;ldots,v_t}" class="latex" /> the set of vertices encountered in the random walk, we have</p>
<p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+P%7D+%5Cleft+%5B+%5Cfrac+1+t+%5Csum_i+f%28v_i%29+%5Cgeq+%5Cmathop%7B%5Cmathbb+E%7D+f+%2B+%5Cepsilon+%5Cright%5D+%5Cleq+e%5E%7B-2%5Cepsilon%5E2+t%7D+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  &#92;mathop{&#92;mathbb P} &#92;left [ &#92;frac 1 t &#92;sum_i f(v_i) &#92;geq &#92;mathop{&#92;mathbb E} f + &#92;epsilon &#92;right] &#92;leq e^{-2&#92;epsilon^2 t} " title="&#92;displaystyle  &#92;mathop{&#92;mathbb P} &#92;left [ &#92;frac 1 t &#92;sum_i f(v_i) &#92;geq &#92;mathop{&#92;mathbb E} f + &#92;epsilon &#92;right] &#92;leq e^{-2&#92;epsilon^2 t} " class="latex" /></p>
<p>
where <img src="https://s0.wp.com/latex.php?latex=%7Bn%3A%3D%7CV%7C%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{n:=|V|}" title="{n:=|V|}" class="latex" />. A corresponding Chernoff-Hoeffding bound can be proved for the case in which the random walk is taken over a regular graph such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_2%28G%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sigma_2(G)}" title="{&#92;sigma_2(G)}" class="latex" /> is small.</p>
<blockquote><p><b>Lemma 3 (Chernoff-Hoeffding Bound for Random Walks in Expanders)</b> <em> Let <img src="https://s0.wp.com/latex.php?latex=%7BG%3D%28V%2CE%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{G=(V,E)}" title="{G=(V,E)}" class="latex" /> be a regular graph, and <img src="https://s0.wp.com/latex.php?latex=%7B%28v_1%2C%5Cldots%2Cv_t%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{(v_1,&#92;ldots,v_t)}" title="{(v_1,&#92;ldots,v_t)}" class="latex" /> the distribution of <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" />-tuples constructed by sampling <img src="https://s0.wp.com/latex.php?latex=%7Bv_1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{v_1}" title="{v_1}" class="latex" /> independently, and then performing a <img src="https://s0.wp.com/latex.php?latex=%7B%28t-1%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{(t-1)}" title="{(t-1)}" class="latex" />-step random walk starting at <img src="https://s0.wp.com/latex.php?latex=%7Bv_1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{v_1}" title="{v_1}" class="latex" />. Let <img src="https://s0.wp.com/latex.php?latex=%7Bf%3A+V+%5Crightarrow+%5B0%2C1%5D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{f: V &#92;rightarrow [0,1]}" title="{f: V &#92;rightarrow [0,1]}" class="latex" /> be any bounded function. Then </p>
<p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+P%7D+%5Cleft%5B+%5Cfrac+1t+%5Csum_i+f%28v_i%29+%5Cgeq+%5Cmathop%7B%5Cmathbb+E%7D+f+%2B+%5Cepsilon%2B+%5Cfrac%7B%5Csigma_2%28G%29+%7D%7Bd%7D+%5Cright%5D+%5Cleq+e%5E%7B-%5COmega%28%5Cepsilon%5E2+t%29%7D+&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="&#92;displaystyle  &#92;mathop{&#92;mathbb P} &#92;left[ &#92;frac 1t &#92;sum_i f(v_i) &#92;geq &#92;mathop{&#92;mathbb E} f + &#92;epsilon+ &#92;frac{&#92;sigma_2(G) }{d} &#92;right] &#92;leq e^{-&#92;Omega(&#92;epsilon^2 t)} " title="&#92;displaystyle  &#92;mathop{&#92;mathbb P} &#92;left[ &#92;frac 1t &#92;sum_i f(v_i) &#92;geq &#92;mathop{&#92;mathbb E} f + &#92;epsilon+ &#92;frac{&#92;sigma_2(G) }{d} &#92;right] &#92;leq e^{-&#92;Omega(&#92;epsilon^2 t)} " class="latex" /></p>
<p> </em></p></blockquote>
<p><p>
We will not prove the above result, but we briefly discuss one of its many applications.</p>
<p>
Suppose that we have a polynomial-time probabilistic algorithm <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{A}" title="{A}" class="latex" /> that, on inputs of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{n}" title="{n}" class="latex" />, uses <img src="https://s0.wp.com/latex.php?latex=%7Br%28n%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{r(n)}" title="{r(n)}" class="latex" /> random bits and then outputs the correct answer with probability, say, at least <img src="https://s0.wp.com/latex.php?latex=%7B2%2F3%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{2/3}" title="{2/3}" class="latex" />. One standard way to reduce the error probability is to run the algorithm <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" /> times, using independent randomness each time, and then take the answer that comes out a majority of the times. (This is for problems in which we want to compute a function exactly; in combinatorial optimization we would run the algorithm <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" /> times and take the best solutions, and in an application in which the algorithm performs an approximate function evaluation we would run the algorithm <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" /> times and take the median. The reasoning that follows for the case of exact function computation can be applied to the other settings as well.)</p>
<p>
On average, the number of iterations of the algorithms that give a correct answer is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cgeq+2t%2F3%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;geq 2t/3}" title="{&#92;geq 2t/3}" class="latex" />, and the cases in which the majority is erroneous correspond to cases in which the number of iterations giving a correct answer is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleq+t%2F2%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;leq t/2}" title="{&#92;leq t/2}" class="latex" />. This means that the case in which the modified algorithm makes a mistake correspond to the case in which the empirical average of <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" /> independent 0/1 random variables deviates from its expectation by more than <img src="https://s0.wp.com/latex.php?latex=%7B2%2F3+-+1%2F2+%3D+1%2F6%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{2/3 - 1/2 = 1/6}" title="{2/3 - 1/2 = 1/6}" class="latex" />, which can happen with probability at most <img src="https://s0.wp.com/latex.php?latex=%7Be%5E%7B-t%2F18%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{e^{-t/18}}" title="{e^{-t/18}}" class="latex" />, which becomes vanishingly small for large <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" />.</p>
<p>
This approach uses <img src="https://s0.wp.com/latex.php?latex=%7Bt%5Ccdot+r%28n%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t&#92;cdot r(n)}" title="{t&#92;cdot r(n)}" class="latex" /> random bits. Suppose, instead, that we consider the following algorithm: pick <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" /> random strings for the algorithm by performing a <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t}" title="{t}" class="latex" />-step random walk in an expander graph of degree <img src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{O(1)}" title="{O(1)}" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Br%28n%29%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{2^{r(n)}}" title="{2^{r(n)}}" class="latex" /> vertices and such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_2%28G%29+%5Cleq+d%2F12%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{&#92;sigma_2(G) &#92;leq d/12}" title="{&#92;sigma_2(G) &#92;leq d/12}" class="latex" />, and then take the majority answer. A calculation using the Chernoff bound for expander graphs show that the error probability is <img src="https://s0.wp.com/latex.php?latex=%7Be%5E%7B-%5COmega%28t%29%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{e^{-&#92;Omega(t)}}" title="{e^{-&#92;Omega(t)}}" class="latex" />, and it is achieved using only <img src="https://s0.wp.com/latex.php?latex=%7Br%28n%29+%2B+O%28t%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{r(n) + O(t)}" title="{r(n) + O(t)}" class="latex" /> random bits instead of <img src="https://s0.wp.com/latex.php?latex=%7Bt%5Ccdot+r%28n%29%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0" alt="{t&#92;cdot r(n)}" title="{t&#92;cdot r(n)}" class="latex" />.</p>
<p><br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/lucatrevisan.wordpress.com/3181/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/lucatrevisan.wordpress.com/3181/" /></a> <img alt="" border="0" src="https://pixel.wp.com/b.gif?host=lucatrevisan.wordpress.com&#038;blog=821887&#038;post=3181&#038;subd=lucatrevisan&#038;ref=&#038;feed=1" width="1" height="1" />]]></content:encoded>
			<wfw:commentRss>https://lucatrevisan.wordpress.com/2016/04/22/cs294-lecture-20-properties-of-expanders/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
	
		<media:content url="http://1.gravatar.com/avatar/1b8146c6b6915dd379892ea751ca5dba?s=96&#38;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D96" medium="image">
			<media:title type="html">luca</media:title>
		</media:content>
	</item>
	</channel>
</rss>
